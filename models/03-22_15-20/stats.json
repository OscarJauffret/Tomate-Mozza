{
    "map_info": {
        "ordered_blocks": "maps/horizon/ordered_blocks.json",
        "list_of_blocks": "maps/horizon/horizon_layout.txt"
    },
    "hyperparameters": {
        "learning_rate": 0.005,
        "gamma": 0.99,
        "max_memory": 100000,
        "batch_size": 128,
        "epsilon_start": 0.9,
        "epsilon_end": 0.05,
        "epsilon_decay": 10000
    },
    "device": "11th Gen Intel(R) Core(TM) i7-11700K @ 3.60GHz",
    "architecture": {
        "inputs": [
            "section_rel_x",
            "section_rel_y",
            "next_turn",
            "in_game_velocity",
            "relative_yaw"
        ],
        "outputs": [
            "forward",
            "right",
            "left",
            "forward_right",
            "forward_left",
            "release"
        ],
        "input_size": 5,
        "output_size": 6,
        "layer_sizes": [
            128,
            128
        ],
        "number_of_hidden_layers": 2,
        "reward_description": "distance travelled projected on the section's x axis (progression on the track)"
    },
    "statistics": {
        "total number of runs": 19,
        "training time": {
            "hours": 0.02638888888888889,
            "milliseconds": 95000
        },
        "average reward": 6.103515625e-05,
        "best reward": 6.103515625e-05,
        "recent average reward": {
            "percentage of runs considered": 0.1,
            "number of runs considered": 2,
            "average reward": 6.103515625e-05
        },
        "lowest rewards average": {
            "percentage of runs considered": 0.1,
            "percentage of low runs considered among the recent ones": 0.1,
            "number of runs considered": 1,
            "average reward": 6.103515625e-05
        },
        "recent quartiles reward": {
            "percentage of runs considered": 0.1,
            "number of runs considered": 2,
            "first quartile": 6.103515625e-05,
            "second quartile": 6.103515625e-05,
            "third quartile": 6.103515625e-05
        }
    },
    "runs": [
        {
            "iteration": 1,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 2,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 3,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 4,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 5,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 5,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 5,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 5,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 5,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 5,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 5,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 5,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 5,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 5,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 6,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 7,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 8,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 9,
            "run_time": 5000,
            "reward": 6.103515625e-05
        },
        {
            "iteration": 10,
            "run_time": 5000,
            "reward": 6.103515625e-05
        }
    ]
}